# ğŸ¤– InstruÃ§Ãµes Completas para Replit AI - GLPI Dashboard

Este documento contÃ©m instruÃ§Ãµes detalhadas para o Replit AI operar o projeto GLPI Dashboard, incluindo execuÃ§Ã£o, correÃ§Ã£o de erros e manutenÃ§Ã£o da integridade arquitetural.

## ğŸ“‹ MANDATÃ“RIO: Regras Fundamentais

### **ğŸš« NUNCA FAÃ‡A ISSO:**
1. **Quebre a arquitetura**: Todas as operaÃ§Ãµes devem usar MetricsFacade como ponto Ãºnico de entrada
2. **Crie scripts em locais incorretos**: Respeite a estrutura de diretÃ³rios definida
3. **Altere sem anÃ¡lise**: Sempre analise completamente antes de qualquer mudanÃ§a
4. **Ignore LSP diagnostics**: Sistema deve manter zero diagnostics sempre
5. **Modifique schemas sem validaÃ§Ã£o**: Schemas sÃ£o fonte Ãºnica da verdade

### **âœ… SEMPRE FAÃ‡A ISSO:**
1. **Analise antes de agir**: Mapeie o problema, entenda o contexto, valide a soluÃ§Ã£o
2. **Use MetricsFacade**: Todos os dados devem passar pelo facade
3. **Mantenha type safety**: Zero LSP diagnostics Ã© obrigatÃ³rio
4. **Teste com mock primeiro**: USE_MOCK_DATA=true para validar mudanÃ§as
5. **Documente alteraÃ§Ãµes**: Atualize README.md e arquivos relevantes

## ğŸš€ Procedimento de InicializaÃ§Ã£o

### **1. VerificaÃ§Ã£o Inicial do Sistema**

```bash
# Execute esta sequÃªncia SEMPRE ao iniciar
echo "=== VerificaÃ§Ã£o Inicial GLPI Dashboard ==="

# 1.1 Verificar estrutura do projeto
if [ ! -f "backend/core/application/services/metrics_facade.py" ]; then
    echo "âŒ ERRO CRÃTICO: MetricsFacade nÃ£o encontrado"
    echo "ğŸ”§ SOLUÃ‡ÃƒO: Restaurar estrutura do projeto"
    exit 1
fi

# 1.2 Verificar configuraÃ§Ã£o
cd backend
if [ ! -f ".env" ]; then
    echo "âŒ ERRO: Arquivo .env nÃ£o encontrado"
    echo "ğŸ”§ SOLUÃ‡ÃƒO: Criar .env baseado no README.md"
fi

# 1.3 Verificar dependÃªncias Python
python -c "
try:
    from config.settings import Config
    from core.application.services.metrics_facade import MetricsFacade
    print('âœ… DependÃªncias OK')
except ImportError as e:
    print(f'âŒ ERRO DE IMPORT: {e}')
    print('ğŸ”§ SOLUÃ‡ÃƒO: pip install -r requirements.txt')
"

# 1.4 Verificar type safety
echo "Verificando LSP diagnostics..."
# Deve retornar "No LSP diagnostics found"

echo "=== VerificaÃ§Ã£o ConcluÃ­da ==="
```

### **2. ConfiguraÃ§Ã£o ObrigatÃ³ria do .env**

```bash
# Sempre validar/criar .env com estas configuraÃ§Ãµes mÃ­nimas:
cat > backend/.env << 'EOF'
# === CONFIGURAÃ‡ÃƒO OBRIGATÃ“RIA ===

# API GLPI - Dados reais (obter do usuÃ¡rio se necessÃ¡rio)
GLPI_URL=http://cau.ppiratini.intra.rs.gov.br/glpi/apirest.php
GLPI_APP_TOKEN=seu_app_token_aqui
GLPI_USER_TOKEN=seu_user_token_aqui

# Modo de dados: false=real, true=mock
USE_MOCK_DATA=false

# SeguranÃ§a
SECRET_KEY=sua_chave_secreta_production_ready

# Cache
REDIS_URL=redis://localhost:6379/0

# Flask
FLASK_ENV=development
FLASK_DEBUG=true

# Alertas
ALERT_RESPONSE_TIME_THRESHOLD=300
ALERT_ERROR_RATE_THRESHOLD=0.05
ALERT_ZERO_TICKETS_THRESHOLD=60
EOF

echo "âœ… Arquivo .env configurado"
```

### **3. InicializaÃ§Ã£o dos ServiÃ§os**

```bash
# 3.1 Backend (Terminal 1)
cd backend
echo "ğŸš€ Iniciando Backend na porta 8000..."
python app.py

# 3.2 Frontend (Terminal 2) 
cd frontend
echo "ğŸš€ Iniciando Frontend na porta 5000..."
npm run dev

# 3.3 VerificaÃ§Ã£o de saÃºde
sleep 5
curl -s http://localhost:8000/api/health | grep -q "status.*ok" && echo "âœ… Backend OK" || echo "âŒ Backend ERROR"
```

## ğŸ”§ Protocolo de CorreÃ§Ã£o de Erros

### **Etapa 1: AnÃ¡lise e Mapeamento**

```bash
# SEMPRE execute esta anÃ¡lise completa antes de corrigir qualquer erro:

echo "=== ANÃLISE COMPLETA DE ERRO ==="

# 1.1 Identificar o erro
echo "1. Coletando informaÃ§Ãµes do erro..."
tail -20 /tmp/logs/Backend_*.log | grep -E "(ERROR|CRITICAL|Exception)"

# 1.2 Verificar arquitetura
echo "2. Validando integridade arquitetural..."
python -c "
from pathlib import Path
facade_path = Path('backend/core/application/services/metrics_facade.py')
routes_path = Path('backend/api/routes.py')

if not facade_path.exists():
    print('âŒ CRÃTICO: MetricsFacade ausente')
    exit(1)

# Verificar se routes usa facade
with open(routes_path) as f:
    content = f.read()
    if 'MetricsFacade' not in content:
        print('âŒ CRÃTICO: Routes nÃ£o usa MetricsFacade')
        exit(1)

print('âœ… Arquitetura Ã­ntegra')
"

# 1.3 Verificar LSP
echo "3. Verificando type safety..."
# LSP diagnostics devem ser zero

# 1.4 Identificar causa raiz
echo "4. Analisando causa raiz..."
# Categorizar: Config, Code, Integration, Infrastructure

echo "=== ANÃLISE CONCLUÃDA ==="
```

### **Etapa 2: EstratÃ©gia de CorreÃ§Ã£o**

```python
# Template para correÃ§Ã£o segura:

def safe_error_correction():
    """
    PROTOCOLO DE CORREÃ‡ÃƒO SEGURA
    """
    
    # 1. BACKUP do estado atual
    backup_current_state()
    
    # 2. ISOLAR o problema
    identify_affected_components()
    
    # 3. TESTAR com mock data primeiro
    switch_to_mock_mode()
    
    # 4. APLICAR correÃ§Ã£o minimal
    apply_minimal_fix()
    
    # 5. VALIDAR funcionamento
    validate_all_endpoints()
    
    # 6. TESTAR com dados reais
    switch_to_real_data()
    
    # 7. CONFIRMAR resoluÃ§Ã£o
    confirm_error_resolved()
```

### **Etapa 3: Casos Comuns de Erro**

#### **Erro de Import/MÃ³dulo**
```bash
# Problema: ModuleNotFoundError, ImportError
# AnÃ¡lise:
echo "ğŸ” ANALISANDO ERRO DE IMPORT..."

# 1. Verificar PYTHONPATH
cd backend
export PYTHONPATH=$(pwd):$PYTHONPATH

# 2. Verificar estrutura de diretÃ³rios
find . -name "*.py" -exec python -m py_compile {} \;

# 3. Verificar dependÃªncias
pip install -r requirements.txt

# 4. CorreÃ§Ã£o tÃ­pica:
# - Corrigir imports relativos
# - Adicionar __init__.py se necessÃ¡rio
# - Verificar estrutura de packages
```

#### **Erro de SerializaÃ§Ã£o/Type**
```bash
# Problema: TypeError, AttributeError com Pydantic
# AnÃ¡lise:
echo "ğŸ” ANALISANDO ERRO DE SERIALIZAÃ‡ÃƒO..."

# REGRA FUNDAMENTAL: Pydantic models NUNCA como dict
# âŒ ERRADO: metrics_data["campo"] = valor
# âœ… CORRETO: metrics_dict = metrics_data.dict(); metrics_dict["campo"] = valor

# Verificar routes.py:
grep -n "metrics_data\[" backend/api/routes.py && echo "âŒ FOUND DIRECT DICT ACCESS"

# CorreÃ§Ã£o padrÃ£o:
sed -i 's/metrics_data\[/metrics_dict[/g' backend/api/routes.py
# Adicionar: metrics_dict = metrics_data.dict() antes do uso
```

#### **Erro de IntegraÃ§Ã£o GLPI**
```bash
# Problema: Connection timeout, Auth failed
# AnÃ¡lise:
echo "ğŸ” ANALISANDO ERRO DE INTEGRAÃ‡ÃƒO GLPI..."

# 1. Testar conectividade
curl -s -w "%{http_code}" "http://cau.ppiratini.intra.rs.gov.br/glpi/apirest.php/initSession" \
  -H "App-Token: $GLPI_APP_TOKEN" \
  -H "Authorization: user_token $GLPI_USER_TOKEN"

# 2. Fallback para mock
echo "USE_MOCK_DATA=true" >> backend/.env

# 3. Verificar tokens
if [ -z "$GLPI_APP_TOKEN" ]; then
    echo "âŒ GLPI_APP_TOKEN nÃ£o configurado"
    # Solicitar ao usuÃ¡rio
fi
```

## ğŸ“Š ValidaÃ§Ã£o e Testes

### **Testes ObrigatÃ³rios ApÃ³s Qualquer AlteraÃ§Ã£o**

```bash
#!/bin/bash
# comprehensive_validation.sh

echo "=== VALIDAÃ‡ÃƒO COMPLETA GLPI DASHBOARD ==="

# 1. Type Safety
echo "1. Verificando type safety..."
# Deve retornar zero LSP diagnostics
check_lsp_diagnostics() {
    # Implementation depends on LSP server
    echo "âœ… Type safety OK"
}

# 2. Architectural Consistency  
echo "2. Verificando consistÃªncia arquitetural..."
python -c "
# Verificar se todas as routes usam MetricsFacade
with open('backend/api/routes.py') as f:
    content = f.read()
    
if 'MetricsFacade' not in content:
    print('âŒ Routes nÃ£o usa MetricsFacade')
    exit(1)
    
if 'metrics_data[' in content:
    print('âŒ Direct dict access em Pydantic model')
    exit(1)
    
print('âœ… Arquitetura consistente')
"

# 3. Functional Tests
echo "3. Testando funcionalidades..."

# 3.1 Health check
curl -s http://localhost:8000/api/health | grep -q "ok" || {
    echo "âŒ Health check failed"
    exit 1
}

# 3.2 Mock data
echo "USE_MOCK_DATA=true" > backend/.env
curl -s http://localhost:8000/api/metrics/v2 | grep -q "total" || {
    echo "âŒ Mock data failed"
    exit 1
}

# 3.3 Real data (se tokens disponÃ­veis)
echo "USE_MOCK_DATA=false" > backend/.env
if [ -n "$GLPI_APP_TOKEN" ]; then
    curl -s http://localhost:8000/api/metrics/v2 | grep -q "total" || {
        echo "âš ï¸ Real data failed - using mock fallback"
        echo "USE_MOCK_DATA=true" > backend/.env
    }
fi

# 4. Performance Tests
echo "4. Verificando performance..."
response_time=$(curl -s -w "%{time_total}" -o /dev/null http://localhost:8000/api/metrics/v2)
if (( $(echo "$response_time > 0.3" | bc -l) )); then
    echo "âš ï¸ Response time alto: ${response_time}s"
fi

echo "=== VALIDAÃ‡ÃƒO CONCLUÃDA âœ… ==="
```

### **Checklist de Qualidade**

```bash
# Execute antes de finalizar qualquer tarefa:

checklist_quality() {
    echo "=== CHECKLIST DE QUALIDADE ==="
    
    # âœ… Type Safety
    check_lsp_diagnostics && echo "âœ… Zero LSP diagnostics" || echo "âŒ LSP issues found"
    
    # âœ… Architecture
    validate_facade_usage && echo "âœ… MetricsFacade usado corretamente" || echo "âŒ Architectural violations"
    
    # âœ… Functionality
    test_all_endpoints && echo "âœ… Todos endpoints funcionando" || echo "âŒ Endpoint failures"
    
    # âœ… Data Integration
    test_mock_and_real_data && echo "âœ… Mock e real data OK" || echo "âŒ Data integration issues"
    
    # âœ… Performance
    check_response_times && echo "âœ… Performance adequada" || echo "âŒ Performance issues"
    
    # âœ… Security
    validate_security_headers && echo "âœ… Security headers OK" || echo "âŒ Security issues"
    
    # âœ… Documentation
    check_documentation_updated && echo "âœ… Docs atualizadas" || echo "âŒ Documentation outdated"
    
    echo "=== CHECKLIST CONCLUÃDO ==="
}
```

## ğŸ—ï¸ Adicionando Novas Features

### **Protocolo para Novas Funcionalidades**

```python
# Template para adicionar nova feature:

def add_new_feature_protocol():
    """
    PROTOCOLO SEGURO PARA NOVAS FEATURES
    """
    
    # 1. DESIGN - Definir schema primeiro
    create_pydantic_schema()  # Em schemas/
    
    # 2. FACADE - Implementar lÃ³gica no facade
    add_method_to_metrics_facade()  # core/application/services/
    
    # 3. ROUTES - Adicionar endpoint
    add_route_using_facade()  # api/routes.py
    
    # 4. MOCK - Implementar dados de teste
    add_mock_data_generator()  # utils/mock_data_generator.py
    
    # 5. TEST - Validar com mock primeiro
    test_with_mock_data()
    
    # 6. INTEGRATE - Testar com dados reais
    test_with_real_data()
    
    # 7. DOCUMENT - Atualizar documentaÃ§Ã£o
    update_readme_and_docs()
```

### **Exemplo PrÃ¡tico: Novo Endpoint**

```python
# 1. SCHEMA (schemas/new_feature.py)
from pydantic import BaseModel
from typing import List, Optional
from datetime import datetime

class NewFeatureResponse(BaseModel):
    data: List[str]
    timestamp: datetime
    metadata: Optional[dict] = None

# 2. FACADE (core/application/services/metrics_facade.py)
def get_new_feature_data(self, params: dict) -> NewFeatureResponse:
    """Nova funcionalidade seguindo padrÃ£o facade."""
    if self.use_mock_data:
        return get_mock_new_feature_data(params)
    
    # Implementar lÃ³gica real
    result = self.glpi_service.fetch_new_feature(params)
    return NewFeatureResponse(
        data=result.data,
        timestamp=datetime.now(),
        metadata=result.metadata
    )

# 3. ROUTE (api/routes.py)
@api_bp.route('/new-feature', methods=['GET'])
@observability_middleware.monitor_endpoint
def get_new_feature():
    try:
        params = request.args.to_dict()
        result = facade.get_new_feature_data(params)
        
        # IMPORTANTE: Usar .dict() para serializaÃ§Ã£o
        response_data = result.dict()
        response_data["_metadata"] = {
            "facade": "MetricsFacade",
            "version": "v1",
            "timestamp": datetime.now().isoformat()
        }
        
        return jsonify(response_data), 200
        
    except Exception as e:
        logger.error(f"Erro em new-feature: {e}")
        return jsonify({"error": str(e)}), 500

# 4. MOCK DATA (utils/mock_data_generator.py)
def get_mock_new_feature_data(params: dict) -> NewFeatureResponse:
    return NewFeatureResponse(
        data=["mock_item_1", "mock_item_2"],
        timestamp=datetime.now(),
        metadata={"source": "mock", "params": params}
    )
```

## ğŸš¨ SituaÃ§Ãµes de EmergÃªncia

### **Sistema Completamente Quebrado**

```bash
# PROCEDIMENTO DE EMERGÃŠNCIA

echo "ğŸš¨ SISTEMA QUEBRADO - INICIANDO RECUPERAÃ‡ÃƒO..."

# 1. Backup rÃ¡pido do estado atual
cp -r backend backend_backup_$(date +%s)

# 2. Reverter para configuraÃ§Ã£o conhecida
git stash  # Salvar mudanÃ§as atuais
git checkout HEAD~1  # Voltar 1 commit

# 3. ConfiguraÃ§Ã£o mÃ­nima funcional
cat > backend/.env << 'EOF'
USE_MOCK_DATA=true
FLASK_ENV=development
FLASK_DEBUG=true
SECRET_KEY=emergency_key_$(date +%s)
EOF

# 4. Restart com mock data
cd backend
python app.py &

# 5. Verificar funcionamento bÃ¡sico
sleep 5
curl http://localhost:8000/api/health || {
    echo "âŒ FALHA NA RECUPERAÃ‡ÃƒO - REQUER INTERVENÃ‡ÃƒO MANUAL"
    exit 1
}

echo "âœ… SISTEMA RECUPERADO EM MODO EMERGÃŠNCIA"
echo "ğŸ‘¥ NOTIFICAR USUÃRIO SOBRE MODO LIMITADO"
```

### **GLPI IndisponÃ­vel**

```bash
# Quando API GLPI nÃ£o responde

echo "âš ï¸ GLPI INDISPONÃVEL - ATIVANDO MODO MOCK..."

# 1. ForÃ§ar modo mock
echo "USE_MOCK_DATA=true" >> backend/.env

# 2. Notificar usuÃ¡rio
echo "ğŸ“¢ SISTEMA EM MODO SIMULAÃ‡ÃƒO"
echo "ğŸ“Š Dados exibidos sÃ£o simulados devido Ã  indisponibilidade do GLPI"
echo "ğŸ”„ RetornarÃ¡ automÃ¡tico quando GLPI estiver disponÃ­vel"

# 3. Monitor GLPI status
(
    while true; do
        if curl -s --max-time 5 "$GLPI_URL" > /dev/null 2>&1; then
            echo "âœ… GLPI DISPONÃVEL NOVAMENTE"
            echo "USE_MOCK_DATA=false" >> backend/.env
            break
        fi
        sleep 300  # Check every 5 minutes
    done
) &
```

## ğŸ“ DocumentaÃ§Ã£o ObrigatÃ³ria

### **Sempre Atualize ApÃ³s MudanÃ§as**

```bash
# Atualizar documentaÃ§Ã£o apÃ³s qualquer alteraÃ§Ã£o significativa:

update_documentation() {
    echo "ğŸ“ Atualizando documentaÃ§Ã£o..."
    
    # 1. README.md - Status do sistema
    update_system_status_in_readme()
    
    # 2. TROUBLESHOOTING.md - Novos problemas encontrados
    document_new_issues_found()
    
    # 3. replit.md - Arquitetura e preferÃªncias
    update_project_architecture()
    
    # 4. ComentÃ¡rios no cÃ³digo
    add_inline_documentation()
    
    echo "âœ… DocumentaÃ§Ã£o atualizada"
}
```

## ğŸ¯ Objetivos de Performance

### **Metas ObrigatÃ³rias**

```bash
# O sistema DEVE atender estes critÃ©rios:

performance_targets() {
    # âœ… Response Time < 300ms (P95)
    check_response_time_p95 && echo "âœ… Response time OK" || echo "âŒ Performance issue"
    
    # âœ… Error Rate < 5%
    check_error_rate && echo "âœ… Error rate OK" || echo "âŒ High error rate"
    
    # âœ… Zero LSP Diagnostics
    check_zero_lsp_diagnostics && echo "âœ… Type safety OK" || echo "âŒ Type issues"
    
    # âœ… Cache Hit Rate > 80%
    check_cache_hit_rate && echo "âœ… Cache efficient" || echo "âŒ Cache issues"
    
    # âœ… Uptime > 99.9%
    check_uptime && echo "âœ… High availability" || echo "âŒ Availability issues"
}
```

---

## ğŸ¯ RESUMO EXECUTIVO PARA REPLIT AI

### **COMANDOS ESSENCIAIS**

```bash
# INICIALIZAÃ‡ÃƒO COMPLETA
cd backend && python app.py &
cd frontend && npm run dev &

# VERIFICAÃ‡ÃƒO DE SAÃšDE
curl http://localhost:8000/api/health

# MODO EMERGÃŠNCIA (mock data)
echo "USE_MOCK_DATA=true" >> backend/.env

# VALIDAÃ‡ÃƒO COMPLETA
./comprehensive_validation.sh
```

### **REGRAS INQUEBRÃVEIS**

1. **MetricsFacade**: Ponto Ãºnico de entrada para dados
2. **Type Safety**: Zero LSP diagnostics sempre
3. **AnÃ¡lise Primeira**: Entender antes de alterar
4. **Mock Primeiro**: Validar com dados simulados
5. **Estrutura Sagrada**: NÃ£o quebrar organizaÃ§Ã£o dos diretÃ³rios

### **EM CASO DE DÃšVIDA**

1. ğŸ” **ANALISE** completamente o problema
2. ğŸ“š **CONSULTE** README.md e TROUBLESHOOTING.md
3. ğŸ§ª **TESTE** com mock data primeiro
4. ğŸ—ï¸ **MANTENHA** arquitetura Ã­ntegra
5. ğŸ“ **DOCUMENTE** mudanÃ§as realizadas

---

**MISSÃƒO:** Manter o GLPI Dashboard funcionando com dados reais, sem dÃ­vida tÃ©cnica, respeitando a arquitetura clean e garantindo experiÃªncia perfeita ao usuÃ¡rio.

**SUCESSO:** Dashboard exibindo mÃ©tricas reais do GLPI com response time < 300ms, zero erros de tipo, e interface responsiva.

---

*Este documento Ã© a referÃªncia autoritativa para operaÃ§Ã£o do GLPI Dashboard. Siga rigorosamente para garantir a integridade do sistema.*